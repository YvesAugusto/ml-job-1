{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4478fd6-999d-4820-9ade-0f087e2f76ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34e3e87-2e5e-4e10-a865-c4266b8b67a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_data(data):\n",
    "    Y = data[data.columns[-1]]\n",
    "    X = data.drop([data.columns[-1]], axis=1)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "DATASETS = []\n",
    "\n",
    "NAMES = [\n",
    "    \"autoprice\", \"linear\", \"sawtooth\"\n",
    "]\n",
    "BASE_DIR = Path(\"../datasets/regressao/\")\n",
    "\n",
    "for name in NAMES:\n",
    "    path = BASE_DIR / name / \"data.csv\"\n",
    "    d = pd.read_csv(str(path), header=None)\n",
    "    DATASETS.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7322dd71-5615-4118-ab0d-1984e7c0c540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def make_grid_params_rbf():\n",
    "    \n",
    "    Cs = np.logspace(-1, 2.1, 5)\n",
    "    Gammas = np.logspace(-2, 2.1, 5)\n",
    "    kernel = np.array([\"rbf\", \"linear\"])\n",
    "\n",
    "    grid = {\n",
    "        \"rbf__C\": Cs,\n",
    "        \"rbf__gamma\": Gammas,\n",
    "        \"rbf__kernel\": kernel,\n",
    "    }\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def make_grid_params_poly():\n",
    "    \n",
    "    Cs = np.logspace(-1, 2.1, 5)\n",
    "    Gammas = np.logspace(-2, 2.1, 5)\n",
    "    kernel = np.array([\"poly\"])\n",
    "    degree = np.array([2, 3, 4])\n",
    "\n",
    "    grid = {\n",
    "        \"poly__C\": Cs,\n",
    "        \"poly__gamma\": Gammas,\n",
    "        \"poly__degree\": degree,\n",
    "        \"poly__kernel\": kernel,\n",
    "    }\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065efafe-f994-4d79-9768-6d45a8fa6c58",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c6f6bd-0faa-4b44-9bc7-3dd06acfccd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 125.89254117941675, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "R²: 0.7927547622449088 +/- 0.022832853780859218\n",
      "{'C': 21.134890398366476, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "R²: 0.999974630052491 +/- 2.7573160542486627e-07\n",
      "{'C': 21.134890398366476, 'gamma': 11.885022274370177, 'kernel': 'rbf'}\n",
      "R²: 0.9935337434600393 +/- 0.0008195089253510663\n"
     ]
    }
   ],
   "source": [
    "plot_colors = \"ryb\"\n",
    "grid = make_grid_params_rbf()\n",
    "for (i, dataset) in enumerate(DATASETS):\n",
    "    \n",
    "    X, Y = parse_data(dataset)\n",
    "    ACCS = []\n",
    "    SENS = []\n",
    "    SPECS = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "    scaler = StandardScaler()\n",
    "    pipeline = Pipeline(steps = [(\"scaler\", scaler), (\"rbf\", SVR())])\n",
    "    \n",
    "    gscv = GridSearchCV(\n",
    "        estimator=pipeline, param_grid=grid, cv=5\n",
    "    )\n",
    "    gscv.fit(X_train, y_train)\n",
    "    best_params = {key.split(\"__\")[-1]: value for key, value in gscv.best_params_.items()}\n",
    "    \n",
    "    print(best_params)\n",
    "    r2 = []\n",
    "    for _ in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "        \n",
    "        # ETAPA DE TREINAMENTO\n",
    "        clf = SVR(**best_params)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # ETAPA DE TESTES\n",
    "        X_test = scaler.transform(X_test)\n",
    "        Y_pred = clf.predict(X_test)\n",
    "        \n",
    "        r2.append(r2_score(y_test, Y_pred))\n",
    "        \n",
    "    print(\"R²: {} +/- {}\".format(\n",
    "        np.mean(r2), np.std(r2)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760b3bfd-6b27-404e-a1ae-93a4687056e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Simple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694df047-745b-4897-8a0c-44d09653ab44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.7795065636159733 +/- 0.013172477469909932\n",
      "R²: 0.9999999998877389 +/- 3.333560819090082e-11\n",
      "R²: 0.7167538323424262 +/- 0.017895084622443498\n"
     ]
    }
   ],
   "source": [
    "plot_colors = \"ryb\"\n",
    "for (i, dataset) in enumerate(DATASETS):\n",
    "    \n",
    "    X, Y = parse_data(dataset)\n",
    "    ACCS = []\n",
    "    SENS = []\n",
    "    SPECS = []\n",
    "    \n",
    "    r2 = []\n",
    "    for _ in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "        \n",
    "        # ETAPA DE TREINAMENTO\n",
    "        clf = LinearRegression()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # ETAPA DE TESTES\n",
    "        X_test = scaler.transform(X_test)\n",
    "        Y_pred = clf.predict(X_test)\n",
    "        \n",
    "        r2.append(r2_score(y_test, Y_pred))\n",
    "        \n",
    "    print(\"R²: {} +/- {}\".format(\n",
    "        np.mean(r2), np.std(r2)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c9b864-b881-4912-84c6-1085b26306b2",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ea6063-f8cd-478f-831b-bb47392f11e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'tree' for estimator Pipeline(steps=[('scaler', StandardScaler()),\n                ('poly', DecisionTreeRegressor())]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m, scaler), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m\"\u001b[39m, DecisionTreeRegressor())])\n\u001b[1;32m     20\u001b[0m gscv \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     21\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline, param_grid\u001b[38;5;241m=\u001b[39mgrid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m gscv\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     24\u001b[0m best_params \u001b[38;5;241m=\u001b[39m {key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m gscv\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_params)\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:674\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parameters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    672\u001b[0m         cloned_parameters[k] \u001b[38;5;241m=\u001b[39m clone(v, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 674\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcloned_parameters)\n\u001b[1;32m    676\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    678\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/sklearn/pipeline.py:211\u001b[0m, in \u001b[0;36mPipeline.set_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set the parameters of this estimator.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    Valid parameter keys can be listed with ``get_params()``. Note that\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m        Pipeline class instance.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_params(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/sklearn/utils/metaestimators.py:70\u001b[0m, in \u001b[0;36m_BaseComposition._set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replace_estimator(attr, name, params\u001b[38;5;241m.\u001b[39mpop(name))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# 3. Step parameters and other initialisation arguments\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/machine-learning/lib/python3.11/site-packages/sklearn/base.py:205\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_params:\n\u001b[1;32m    204\u001b[0m     local_valid_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names()\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid parameters are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_valid_params\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delim:\n\u001b[1;32m    211\u001b[0m     nested_params[key][sub_key] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter 'tree' for estimator Pipeline(steps=[('scaler', StandardScaler()),\n                ('poly', DecisionTreeRegressor())]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "plot_colors = \"ryb\"\n",
    "grid = {\n",
    "    'tree__max_depth': [2, 4, 6, 8, 10, 12],\n",
    "    'tree__min_samples_split': [2, 4, 6, 8, 10, 12],\n",
    "}\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "for (i, dataset) in enumerate(DATASETS):\n",
    "    \n",
    "    X, Y = parse_data(dataset)\n",
    "    ACCS = []\n",
    "    SENS = []\n",
    "    SPECS = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "    scaler = StandardScaler()\n",
    "    pipeline = Pipeline(steps = [(\"scaler\", scaler), (\"tree\", DecisionTreeRegressor())])\n",
    "    \n",
    "    gscv = GridSearchCV(\n",
    "        estimator=pipeline, param_grid=grid, cv=5\n",
    "    )\n",
    "    gscv.fit(X_train, y_train)\n",
    "    best_params = {key.split(\"__\")[-1]: value for key, value in gscv.best_params_.items()}\n",
    "    \n",
    "    print(best_params)\n",
    "    r2 = []\n",
    "    for _ in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "        \n",
    "        # ETAPA DE TREINAMENTO\n",
    "        clf = DecisionTreeRegressor(**best_params)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # ETAPA DE TESTES\n",
    "        X_test = scaler.transform(X_test)\n",
    "        Y_pred = clf.predict(X_test)\n",
    "        \n",
    "        r2.append(r2_score(y_test, Y_pred))\n",
    "        \n",
    "    print(\"R²: {} +/- {}\".format(\n",
    "        np.mean(r2), np.std(r2)\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
